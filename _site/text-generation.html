<h3 id="state-of-the-art-in-text-generation">State Of The Art in Text Generation</h3>

<h3 id="coco-captions">COCO Captions</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1709.08624v2.pdf"> Long Text Generation via Adversarial Training with Leaked Information</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/CR-Gjx/LeakGAN">LeakGAN</a></p>
  </li>
  <li>
    <p>Last Update: 2018-03-17</p>
  </li>
</ul>

<h3 id="chinese-poems">Chinese Poems</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1709.08624v2.pdf"> Long Text Generation via Adversarial Training with Leaked Information</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/CR-Gjx/LeakGAN">LeakGAN</a></p>
  </li>
  <li>
    <p>Last Update: 2018-03-17</p>
  </li>
</ul>

<h3 id="emnlp2017-wmt">EMNLP2017 WMT</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1709.08624v2.pdf"> Long Text Generation via Adversarial Training with Leaked Information</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/CR-Gjx/LeakGAN">LeakGAN</a></p>
  </li>
  <li>
    <p>Last Update: 2018-03-17</p>
  </li>
</ul>

<h3 id="yahoo-questions">Yahoo Questions</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1901.05534v2.pdf">ICLR 2019 Lagging Inference Networks and Posterior Collapse in Variational Autoencoders</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/jxhe/vae-lagging-encoder">Aggressive VAE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-04-16</p>
  </li>
</ul>

<h3 id="cmu-se">CMU-SE</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1808.08703v2.pdf"> Generating Text through Adversarial Training using Skip-Thought Vectors</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/enigmaeth/skip-thought-gan">STWGAN-GP</a></p>
  </li>
  <li>
    <p>Last Update: 2019-03-20</p>
  </li>
</ul>

<h3 id="dailydialog">DailyDialog</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1808.08795v1.pdf">EMNLP 2018 An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/lancopku/AMM">AEM+Attention</a></p>
  </li>
  <li>
    <p>Last Update: 2018-08-27</p>
  </li>
</ul>

<h3 id="ldc2016e25">LDC2016E25</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1805.02473v3.pdf">ACL 2018 A Graph-to-Sequence Model for AMR-to-Text Generation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="">Graph2Seq</a></p>
  </li>
</ul>

