<h3 id="state-of-the-art-in-speech-recognition">State Of The Art in Speech Recognition</h3>

<h3 id="switchboard--hub500">Switchboard + Hub500</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1703.02136v1.pdf"> English Conversational Telephone Speech Recognition by Humans and Machines</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="">ResNet + BiLSTMs acoustic model</a></p>
  </li>
</ul>

<h3 id="timit">TIMIT</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1811.07453v2.pdf"> The PyTorch-Kaldi Speech Recognition Toolkit</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/mravanelli/pytorch-kaldi">LiGRU + Dropout + BatchNorm + Monophone Reg</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-07</p>
  </li>
</ul>

<h3 id="librispeech-test-clean">LibriSpeech test-clean</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1904.08779v1.pdf"> SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/shelling203/SpecAugment">LAS + SpecAugment</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-07</p>
  </li>
</ul>

<h3 id="swb_hub_500-wer-fullswbch">swb_hub_500 WER fullSWBCH</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1703.02136v1.pdf"> English Conversational Telephone Speech Recognition by Humans and Machines</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="">ResNet + BiLSTMs acoustic model</a></p>
  </li>
</ul>

<h3 id="librispeech-test-other">LibriSpeech test-other</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1904.08779v1.pdf"> SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/shelling203/SpecAugment">LAS + SpecAugment</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-07</p>
  </li>
</ul>

<h3 id="wsj-eval92">WSJ eval92</h3>

<ul>
  <li>
    <p>Paper: <a href="https://www.danielpovey.com/files/2016_interspeech_mmi.pdf">INTERSPEECH 2016 2016 Purely sequence-trained neural networks for ASR based on lattice-free MMI</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/kaldi-asr/kaldi">tdnn + chain</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-07</p>
  </li>
</ul>

<h3 id="wsj-eval93">WSJ eval93</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1512.02595v1.pdf"> Deep Speech 2: End-to-End Speech Recognition in English and Mandarin</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/deep_speech">Deep Speech 2</a></p>
  </li>
  <li>
    <p>Last Update: 2019-04-29</p>
  </li>
</ul>

<h3 id="librispeech">Librispeech</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1810.04826v4.pdf"> VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/mindslab-ai/voicefilter">VoiceFilter: bi-LSTM</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-03</p>
  </li>
</ul>

<h3 id="switchboard-300hr">Switchboard (300hr)</h3>

<ul>
  <li>
    <p>Paper: <a href="https://www.danielpovey.com/files/2018_interspeech_end2end.pdf">Interspeech 2018 2018 End-to-end speech recognition using lattice-free MMI</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/kaldi-asr/kaldi">End-to-end LF-MMI</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-07</p>
  </li>
</ul>

