<h3 id="state-of-the-art-in-image-retrieval">State Of The Art in Image Retrieval</h3>

<h3 id="oxf5k">Oxf5k</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1612.06321v4.pdf">ICCV 2017 Large-Scale Image Retrieval with Attentive Deep Local Features</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/delf">DELF+FT+ATT+DIR+QE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-29</p>
  </li>
</ul>

<h3 id="par6k">Par6k</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1612.06321v4.pdf">ICCV 2017 Large-Scale Image Retrieval with Attentive Deep Local Features</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/delf">DELF+FT+ATT+DIR+QE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-29</p>
  </li>
</ul>

<h3 id="par106k">Par106k</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1612.06321v4.pdf">ICCV 2017 Large-Scale Image Retrieval with Attentive Deep Local Features</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/delf">DELF+FT+ATT+DIR+QE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-29</p>
  </li>
</ul>

<h3 id="oxf105k">Oxf105k</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1612.06321v4.pdf">ICCV 2017 Large-Scale Image Retrieval with Attentive Deep Local Features</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/delf">DELF+FT+ATT+DIR+QE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-29</p>
  </li>
</ul>

<h3 id="inria-holidays">INRIA Holidays</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1902.05509v2.pdf"> MultiGrain: a unified image embedding for classes and instances</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/facebookresearch/multigrain">MultiGrain R50 @ 800</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-10</p>
  </li>
</ul>

<h3 id="street2shop---topwear">street2shop - topwear</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1901.03546v1.pdf"> Retrieving Similar E-Commerce Images Using Deep Learning</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/gofynd/mildnet">Ranknet</a></p>
  </li>
  <li>
    <p>Last Update: 2019-04-09</p>
  </li>
</ul>

<h3 id="nus-wide">NUS-WIDE</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1902.00153v1.pdf"> Deep Triplet Quantization</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/thulab/DeepHash">DTQ</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-29</p>
  </li>
</ul>

<h3 id="stanford-cars">Stanford Cars</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1804.00382v2.pdf">ECCV 2018 Attention-based Ensemble for Deep Metric Learning</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="">ABE-8-512</a></p>
  </li>
</ul>

