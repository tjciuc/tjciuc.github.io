---
path: '/stuff/'
title: 'Visual Question Answering'
type: 'COMPUTER_VISION'

layout: nil
---

### State Of The Art in Visual Question Answering  

### COCO Visual Question Answering (VQA) real images 1.0 open ended

* Paper: [EMNLP 2016 Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](https://arxiv.org/pdf/1606.01847v3.pdf)

* Best Method and Code: [MCB 7 att.](https://github.com/Cadene/vqa.pytorch)

* Last Update: 2019-02-24

### VQA v2

* Paper: [CVPR 2018 Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge](https://arxiv.org/pdf/1708.02711v1.pdf)

* Best Method and Code: [Image features from bottom-up attention, adaptive K, ensemble](https://github.com/peteanderson80/bottom-up-attention)

* Last Update: 2018-05-04

### COCO Visual Question Answering (VQA) real images 1.0 multiple choice

* Paper: [EMNLP 2016 Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](https://arxiv.org/pdf/1606.01847v3.pdf)

* Best Method and Code: [MCB 7 att.](https://github.com/Cadene/vqa.pytorch)

* Last Update: 2019-02-24

### COCO Visual Question Answering (VQA) real images 2.0 open ended

* Paper: [CVPR 2018 Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://arxiv.org/pdf/1707.07998v3.pdf)

* Best Method and Code: [Up-Down](https://github.com/peteanderson80/bottom-up-attention)

* Last Update: 2018-05-04

### COCO Visual Question Answering (VQA) abstract images 1.0 open ended

* Paper: [CVPR 2017 Graph-Structured Representations for Visual Question Answering](https://arxiv.org/pdf/1609.05600v2.pdf)

* Best Method and Code: [Graph VQA]()

### COCO Visual Question Answering (VQA) abstract 1.0 multiple choice

* Paper: [CVPR 2017 Graph-Structured Representations for Visual Question Answering](https://arxiv.org/pdf/1609.05600v2.pdf)

* Best Method and Code: [Graph VQA]()

### Visual7W

* Paper: [CVPR 2017 Modeling Relationships in Referential Expressions with Compositional Modular Networks](https://arxiv.org/pdf/1611.09978v1.pdf)

* Best Method and Code: [CMN](https://github.com/hengyuan-hu/bottom-up-attention-vqa)

* Last Update: 2018-05-05

### Visual Genome (subjects)

* Paper: [CVPR 2017 Modeling Relationships in Referential Expressions with Compositional Modular Networks](https://arxiv.org/pdf/1611.09978v1.pdf)

* Best Method and Code: [CMN](https://github.com/hengyuan-hu/bottom-up-attention-vqa)

* Last Update: 2018-05-05

### Visual Genome (pairs)

* Paper: [CVPR 2017 Modeling Relationships in Referential Expressions with Compositional Modular Networks](https://arxiv.org/pdf/1611.09978v1.pdf)

* Best Method and Code: [CMN](https://github.com/hengyuan-hu/bottom-up-attention-vqa)

* Last Update: 2018-05-05

### VizWiz

* Paper: [CVPR 2018 Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge](https://arxiv.org/pdf/1708.02711v1.pdf)

* Best Method and Code: [Pythia v0.3](https://github.com/peteanderson80/bottom-up-attention)

* Last Update: 2018-05-04

