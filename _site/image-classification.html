<h3 id="state-of-the-art-in-image-classification">State Of The Art in Image Classification</h3>

<h3 id="cifar-10">CIFAR-10</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1811.06965v4.pdf"> GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/lingvo">GPIPE + transfer learning</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-09</p>
  </li>
</ul>

<h3 id="mnist">MNIST</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1805.01890v2.pdf"> RMDL: Random Multimodel Deep Learning for Classification</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/kk7nc/RMDL">RMDL</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-31</p>
  </li>
</ul>

<h3 id="cifar-100">CIFAR-100</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1811.06965v4.pdf"> GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/lingvo">GPIPE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-09</p>
  </li>
</ul>

<h3 id="imagenet">ImageNet</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1811.06965v4.pdf"> GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/lingvo">GPIPE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-09</p>
  </li>
</ul>

<h3 id="svhn">SVHN</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1901.09321v2.pdf">ICLR 2019 Fixup Initialization: Residual Learning Without Normalization</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/hongyi-zhang/Fixup">WRN + fixup init + mixup + cutout</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-05</p>
  </li>
</ul>

<h3 id="stl-10">STL-10</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1807.06653.pdf">arXiv 2019 Invariant Information Clustering for Unsupervised Image Classification and Segmentation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/xu-ji/IIC">IIC</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-02</p>
  </li>
</ul>

<h3 id="cinic-10">CINIC-10</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1810.03505v1.pdf"> CINIC-10 is not ImageNet or CIFAR-10</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/BayesWatch/cinic-10">ResNeXt29_2x64d</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-06</p>
  </li>
</ul>

<h3 id="fashion-mnist">Fashion-MNIST</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1708.04896v2.pdf"> Random Erasing Data Augmentation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/zhunzhong07/Random-Erasing">Random Erasing</a></p>
  </li>
  <li>
    <p>Last Update: 2019-06-07</p>
  </li>
</ul>

<h3 id="kuzushiji-mnist">Kuzushiji-MNIST</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1901.06656v2.pdf"> Training Neural Networks with Local Error Signals</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/anokland/local-loss">VGG8B+LocalLearning+CO</a></p>
  </li>
  <li>
    <p>Last Update: 2019-01-23</p>
  </li>
</ul>

<h3 id="inaturalist">iNaturalist</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1707.06642v2.pdf">CVPR 2018 The iNaturalist Species Classification and Detection Dataset</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">IncResNetV2 SE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-31</p>
  </li>
</ul>

<h3 id="multimnist">MultiMNIST</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1710.09829v2.pdf">NeurIPS 2017 Dynamic Routing Between Capsules</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/naturomics/CapsNet-Tensorflow">CapsNet</a></p>
  </li>
  <li>
    <p>Last Update: 2018-09-14</p>
  </li>
</ul>

