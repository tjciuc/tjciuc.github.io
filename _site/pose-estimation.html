<h3 id="state-of-the-art-in-pose-estimation">State Of The Art in Pose Estimation</h3>

<h3 id="mpii-human-pose">MPII Human Pose</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1902.09212v1.pdf">CVPR 2019 Deep High-Resolution Representation Learning for Human Pose Estimation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/leoxiaobin/deep-high-resolution-net.pytorch">HRNet-32</a></p>
  </li>
  <li>
    <p>Last Update: 2019-04-11</p>
  </li>
</ul>

<h3 id="leeds-sports-poses">Leeds Sports Poses</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1708.01101v1.pdf">ICCV 2017 Learning Feature Pyramids for Human Pose Estimation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/bearpaw/PyraNet">Pyramid Residual Modules (PRMs)</a></p>
  </li>
  <li>
    <p>Last Update: 2017-11-13</p>
  </li>
</ul>

<h3 id="flic-wrists">FLIC Wrists</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1603.06937v2.pdf"> Stacked Hourglass Networks for Human Pose Estimation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/bearpaw/pytorch-pose">Stacked Hourglass Networks</a></p>
  </li>
  <li>
    <p>Last Update: 2019-02-25</p>
  </li>
</ul>

<h3 id="itop-front-view">ITOP front-view</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1711.07399v3.pdf">CVPR 2018 V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and Human Pose Estimation from a Single Depth Map</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/mks0601/V2V-PoseNet_RELEASE">V2V-PoseNet</a></p>
  </li>
  <li>
    <p>Last Update: 2019-02-26</p>
  </li>
</ul>

<h3 id="itop-top-view">ITOP top-view</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1711.07399v3.pdf">CVPR 2018 V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and Human Pose Estimation from a Single Depth Map</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/mks0601/V2V-PoseNet_RELEASE">V2V-PoseNet</a></p>
  </li>
  <li>
    <p>Last Update: 2019-02-26</p>
  </li>
</ul>

<h3 id="densepose-coco">DensePose-COCO</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1811.12596v1.pdf">CVPR 2019 Parsing R-CNN for Instance-Level Human Analysis</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/soeaver/Parsing-R-CNN">Parsing R-CNN + ResNext101</a></p>
  </li>
  <li>
    <p>Last Update: 2018-12-03</p>
  </li>
</ul>

<h3 id="coco">COCO</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1902.09212v1.pdf">CVPR 2019 Deep High-Resolution Representation Learning for Human Pose Estimation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/leoxiaobin/deep-high-resolution-net.pytorch">HRNet-48</a></p>
  </li>
  <li>
    <p>Last Update: 2019-04-11</p>
  </li>
</ul>

<h3 id="flic-elbows">FLIC Elbows</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1603.06937v2.pdf"> Stacked Hourglass Networks for Human Pose Estimation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/bearpaw/pytorch-pose">Stacked Hourglass Networks</a></p>
  </li>
  <li>
    <p>Last Update: 2019-02-25</p>
  </li>
</ul>

