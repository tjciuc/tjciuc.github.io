---
path: '/stuff/'
title: 'Text Generation'
type: 'NATURAL_LANGUAGE_PROCESSING'

layout: nil
---

### State Of The Art in Text Generation  
### 文本生成的最新进展  

### COCO Captions

* Paper: [Long Text Generation via Adversarial Training with Leaked Information](https://arxiv.org/pdf/1709.08624v2.pdf)

* Best Method and Code: [LeakGAN](https://github.com/CR-Gjx/LeakGAN)

* Last Update: 2018-03-17

* 论文: [利用泄漏信息进行对抗性训练生成长文本](https://arxiv.org/pdf/1709.08624v2.pdf)

* 最佳方法和代码: [LeakGAN](https://github.com/CR-Gjx/LeakGAN)

* 最近更新: 2018-03-17

### Chinese Poems

* Paper: [Long Text Generation via Adversarial Training with Leaked Information](https://arxiv.org/pdf/1709.08624v2.pdf)

* Best Method and Code: [LeakGAN](https://github.com/CR-Gjx/LeakGAN)

* Last Update: 2018-03-17

* 论文: [利用泄漏信息进行对抗性训练生成长文本](https://arxiv.org/pdf/1709.08624v2.pdf)

* 最佳方法和代码: [LeakGAN](https://github.com/CR-Gjx/LeakGAN)

* 最近更新: 2018-03-17

### EMNLP2017 WMT

* Paper: [Long Text Generation via Adversarial Training with Leaked Information](https://arxiv.org/pdf/1709.08624v2.pdf)

* Best Method and Code: [LeakGAN](https://github.com/CR-Gjx/LeakGAN)

* Last Update: 2018-03-17

* 论文: [利用泄漏信息进行对抗性训练生成长文本](https://arxiv.org/pdf/1709.08624v2.pdf)

* 最佳方法和代码: [LeakGAN](https://github.com/CR-Gjx/LeakGAN)

* 最近更新: 2018-03-17

### Yahoo Questions

* Paper: [ICLR 2019 Lagging Inference Networks and Posterior Collapse in Variational Autoencoders](https://arxiv.org/pdf/1901.05534v2.pdf)

* Best Method and Code: [Aggressive VAE](https://github.com/jxhe/vae-lagging-encoder)

* Last Update: 2019-04-16

* 论文: [ICLR 2019 变分自编码器中的滞后推理网络与后崩塌](https://arxiv.org/pdf/1901.05534v2.pdf)

* 最佳方法和代码: [Aggressive VAE](https://github.com/jxhe/vae-lagging-encoder)

* 最近更新: 2019-04-16

### CMU-SE

* Paper: [Generating Text through Adversarial Training using Skip-Thought Vectors](https://arxiv.org/pdf/1808.08703v2.pdf)

* Best Method and Code: [STWGAN-GP](https://github.com/enigmaeth/skip-thought-gan)

* Last Update: 2019-03-20

* 论文: [基于Skip-Thought向量用对抗式训练生成文本](https://arxiv.org/pdf/1808.08703v2.pdf)

* 最佳方法和代码: [STWGAN-GP](https://github.com/enigmaeth/skip-thought-gan)

* 最近更新: 2019-03-20

### DailyDialog

* Paper: [EMNLP 2018 An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation](https://arxiv.org/pdf/1808.08795v1.pdf)

* Best Method and Code: [AEM+Attention](https://github.com/lancopku/AMM)

* Last Update: 2018-08-27

* 论文: [EMNLP 2018 对话生成中学习话语层语义依存的自编码器匹配模型](https://arxiv.org/pdf/1808.08795v1.pdf)

* 最佳方法和代码: [AEM+Attention](https://github.com/lancopku/AMM)

* 最近更新: 2018-08-27

### LDC2016E25

* Paper: [ACL 2018 A Graph-to-Sequence Model for AMR-to-Text Generation](https://arxiv.org/pdf/1805.02473v3.pdf)

* Best Method and Code: [Graph2Seq]()

* 论文: [ACL 2018 从AMR到文本生成的图到序列模型](https://arxiv.org/pdf/1805.02473v3.pdf)

* 最佳方法和代码: [Graph2Seq]()


