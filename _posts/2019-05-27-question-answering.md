---
path: '/stuff/'
title: 'Question Answering'
type: 'COMPUTER_VISION'

layout: nil
---

### State Of The Art in Question Answering  
### 智能问答的最新进展  

### SQuAD1.1

* Paper: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805v1.pdf)

* Best Method and Code: [BERT (ensemble)](https://github.com/google-research/bert)

* Last Update: 2019-05-31

* 论文: [BERT: 预训练深度双向编码器用于语言理解](https://arxiv.org/pdf/1810.04805v1.pdf)

* 最佳方法和代码: [BERT (ensemble)](https://github.com/google-research/bert)

* 最近更新: 2019-05-31

### CNN / Daily Mail

* Paper: [Linguistic Knowledge as Memory for Recurrent Neural Networks](https://arxiv.org/pdf/1703.02620v1.pdf)

* Best Method and Code: [GA+MAGE (32)]()

* 论文: [基于语言知识的循环神经网络](https://arxiv.org/pdf/1703.02620v1.pdf)

* 最佳方法和代码: [GA+MAGE (32)]()

### WikiQA

* Paper: [Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering](https://arxiv.org/pdf/1707.07847v3.pdf)

* Best Method and Code: [HyperQA](https://github.com/vanzytay/WSDM2018_HyperQA)

* Last Update: 2018-06-13

* 论文: [快速高效的神经网络问答的双曲线表示学习](https://arxiv.org/pdf/1707.07847v3.pdf)

* 最佳方法和代码: [HyperQA](https://github.com/vanzytay/WSDM2018_HyperQA)

* 最近更新: 2018-06-13

### bAbi

* Paper: [Query-Reduction Networks for Question Answering](https://arxiv.org/pdf/1606.04582v6.pdf)

* Best Method and Code: [QRN](https://github.com/uwnlp/qrn)

* Last Update: 2017-09-03

* 论文: [用于问答的简化查询网络](https://arxiv.org/pdf/1606.04582v6.pdf)

* 最佳方法和代码: [QRN](https://github.com/uwnlp/qrn)

* 最近更新: 2017-09-03

### Children's Book Test

* Paper: [Preprint 2019 Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)

* Best Method and Code: [GPT-2](https://github.com/openai/gpt-2)

* Last Update: 2019-05-31

* 论文: [Preprint 2019 语言模型是非监督多任务学习器](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)

* 最佳方法和代码: [GPT-2](https://github.com/openai/gpt-2)

* 最近更新: 2019-05-31

### CoQA

* Paper: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805v1.pdf)

* Best Method and Code: [BERT Large Augmented (single model)](https://github.com/google-research/bert)

* Last Update: 2019-05-31

* 论文: [BERT: 预训练深度双向编码器用于语言理解](https://arxiv.org/pdf/1810.04805v1.pdf)

* 最佳方法和代码: [BERT (ensemble)](https://github.com/google-research/bert)

* 最近更新: 2019-05-31

### QASent

* Paper: [Neural Variational Inference for Text Processing](https://arxiv.org/pdf/1511.06038v4.pdf)

* Best Method and Code: [Attentive LSTM](https://github.com/carpedm20/variational-text-tensorflow)

* Last Update: 2016-08-10

* 论文: [文本处理中的神经网络变分推断](https://arxiv.org/pdf/1511.06038v4.pdf)

* 最佳方法和代码: [Attentive LSTM](https://github.com/carpedm20/variational-text-tensorflow)

* 最近更新: 2016-08-10

### NarrativeQA

* Paper: [EMNLP 2018 Cut to the Chase: A Context Zoom-in Network for Reading Comprehension](http://aclweb.org/anthology/D18-1054)

* Best Method and Code: [ConZNet]()

* 论文: [EMNLP 2018 直截了当: 用于阅读理解的上下文放大网络](http://aclweb.org/anthology/D18-1054)

* 最佳方法和代码: [ConZNet]()

### TriviaQA

* Paper: [EMNLP 2018 MemoReader: Large-Scale Reading Comprehension through Neural Memory Controller](http://aclweb.org/anthology/D18-1237)

* Best Method and Code: [MemoReader]()

* 论文: [EMNLP 2018 MemoReader: 利用神经网络记忆控制器的大规模阅读理解](http://aclweb.org/anthology/D18-1237)

* 最佳方法和代码: [MemoReader]()

### YahooCQA

* Paper: [Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering](https://arxiv.org/pdf/1707.07847v3.pdf)

* Best Method and Code: [HyperQA](https://github.com/vanzytay/WSDM2018_HyperQA)

* Last Update: 2018-06-13

* 论文: [快速高效的神经网络问答的双曲线表示学习](https://arxiv.org/pdf/1707.07847v3.pdf)

* 最佳方法和代码: [HyperQA](https://github.com/vanzytay/WSDM2018_HyperQA)

* 最近更新: 2018-06-13

### SemEvalCQA

* Paper: [Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering](https://arxiv.org/pdf/1707.07847v3.pdf)

* Best Method and Code: [HyperQA](https://github.com/vanzytay/WSDM2018_HyperQA)

* Last Update: 2018-06-13

* 论文: [快速高效的神经网络问答的双曲线表示学习](https://arxiv.org/pdf/1707.07847v3.pdf)

* 最佳方法和代码: [HyperQA](https://github.com/vanzytay/WSDM2018_HyperQA)

* 最近更新: 2018-06-13

### WikiHop

* Paper: [ICLR 2019 Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering](https://arxiv.org/pdf/1901.00603v2.pdf)

* Best Method and Code: [CFC]()

* 论文: [ICLR 2019 用于多证据问答的粗细粒结合网络](https://arxiv.org/pdf/1901.00603v2.pdf)

* 最佳方法和代码: [CFC]()

### AI2 Kaggle Dataset

* Paper: [CONLL 2017 Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification](http://aclweb.org/anthology/K17-1009)

* Best Method and Code: [IR Baseline]()

* Paper: [CONLL 2017 告诉我为什么: 利用问答作为检验答案的远程监督](http://aclweb.org/anthology/K17-1009)

* Best Method and Code: [IR Baseline]()

### TrecQA

* Paper: [Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering](https://arxiv.org/pdf/1707.07847v3.pdf)

* Best Method and Code: [HyperQA](https://github.com/vanzytay/WSDM2018_HyperQA)

* Last Update: 2018-06-13

* 论文: [快速高效的神经网络问答的双曲线表示学习](https://arxiv.org/pdf/1707.07847v3.pdf)

* 最佳方法和代码: [HyperQA](https://github.com/vanzytay/WSDM2018_HyperQA)

* 最近更新: 2018-06-13

### MS MARCO

* Paper: [Multi-style Generative Reading Comprehension](https://arxiv.org/pdf/1901.02262v1.pdf)

* Best Method and Code: [Masque Q&A Style]()

* 论文: [多风格生成式阅读理解](https://arxiv.org/pdf/1901.02262v1.pdf)

* 最佳方法和代码: [Masque Q&A Style]()

### NewsQA

* Paper: [NeurIPS 2018 Densely Connected Attention Propagation for Reading Comprehension](https://arxiv.org/pdf/1811.04210v2.pdf)

* Best Method and Code: [DecaProp](https://github.com/vanzytay/NIPS2018_DECAPROP)

* Last Update: 2019-03-10

* 论文: [NeurIPS 2018 阅读理解中密集连接的注意力传播](https://arxiv.org/pdf/1811.04210v2.pdf)

* 最佳方法和代码: [DecaProp](https://github.com/vanzytay/NIPS2018_DECAPROP)

* 最近更新: 2019-03-10

### WebQuestions

* Paper: [Large-scale Simple Question Answering with Memory Networks](https://arxiv.org/pdf/1506.02075v1.pdf)

* Best Method and Code: [Memory Networks (ensemble)](https://github.com/facebookresearch/ParlAI)

* Last Update: 2019-06-07

* 论文: [基于记忆网络的大规模简单问答](https://arxiv.org/pdf/1506.02075v1.pdf)

* 最佳方法和代码: [Memory Networks (ensemble)](https://github.com/facebookresearch/ParlAI)

* 最近更新: 2019-06-07

### CliCR

* Paper: [HLT 2018 CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension](http://aclweb.org/anthology/N18-1140)

* Best Method and Code: [Gated-Attention Reader]()

* 论文: [HLT 2018 CliCR: 一个用于机器阅读理解的临床病例报告数据集](http://aclweb.org/anthology/N18-1140)

* 最佳方法和代码: [Gated-Attention Reader]()

### Reverb

* Paper: [Open Question Answering with Weakly Supervised Embedding Models](https://arxiv.org/pdf/1404.4326v1.pdf)

* Best Method and Code: [Weakly Supervised Embeddings]()

* 论文: [具有弱监督嵌入模型的开放式问答](https://arxiv.org/pdf/1404.4326v1.pdf)

* 最佳方法和代码: [Weakly Supervised Embeddings]()

### MCTest-500

* Paper: [ACL 2016 A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data](https://arxiv.org/pdf/1603.08884v1.pdf)

* Best Method and Code: [Parallel-Hierarchical](https://github.com/Maluuba/mctest-model)

* Last Update: 2018-11-20

* 论文: [ACL 2016 用于稀疏数据机器理解的并行分层模型](https://arxiv.org/pdf/1603.08884v1.pdf)

* 最佳方法和代码: [Parallel-Hierarchical](https://github.com/Maluuba/mctest-model)

* 最近更新: 2018-11-20

### QuAC

* Paper: [ICLR 2019 FlowQA: Grasping Flow in History for Conversational Machine Comprehension](https://arxiv.org/pdf/1810.06683v3.pdf)

* Best Method and Code: [FlowQA (single model)](https://github.com/momohuang/FlowQA)

* Last Update: 2018-11-22

* 论文: [ICLR 2019 FlowQA: 在对话式机器理解中抓取历史中的流](https://arxiv.org/pdf/1810.06683v3.pdf)

* 最佳方法和代码: [FlowQA (single model)](https://github.com/momohuang/FlowQA)

* 最近更新: 2018-11-22

### Quora Question Pairs

* Paper: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805v1.pdf)

* Best Method and Code: [BERT (single model)](https://github.com/google-research/bert)

* Last Update: 2019-05-31

* 论文: [BERT: 预训练深度双向编码器用于语言理解](https://arxiv.org/pdf/1810.04805v1.pdf)

* 最佳方法和代码: [BERT (ensemble)](https://github.com/google-research/bert)

* 最近更新: 2019-05-31

### COMPLEXQUESTIONS

* Paper: [SEMEVAL 2017 Evaluating Semantic Parsing against a Simple Web-based Question Answering Model](https://arxiv.org/pdf/1707.04412v1.pdf)

* Best Method and Code: [WebQA]()

* 论文: [SEMEVAL 2017 一个简单基于Web问答模型的语义分析评估](https://arxiv.org/pdf/1707.04412v1.pdf)

* 最佳方法和代码: [WebQA]()

### SimpleQuestions

* Paper: [Large-scale Simple Question Answering with Memory Networks](https://arxiv.org/pdf/1506.02075v1.pdf)

* Best Method and Code: [Memory Networks (ensemble)](https://github.com/facebookresearch/ParlAI)

* Last Update: 2019-06-07

* 论文: [基于记忆网络的大规模简单问答](https://arxiv.org/pdf/1506.02075v1.pdf)

* 最佳方法和代码: [Memory Networks (ensemble)](https://github.com/facebookresearch/ParlAI)

* 最近更新: 2019-06-07

### Natural Questions

* Paper: [A BERT Baseline for the Natural Questions](https://arxiv.org/pdf/1901.08634v2.pdf)

* Best Method and Code: [BERT-joint]()

* 论文: [自然问题的BERT基线](https://arxiv.org/pdf/1901.08634v2.pdf)

* 最佳方法和代码: [BERT-joint]()

### JD Product Question Answer

* Paper: [Product-Aware Answer Generation in E-Commerce Question-Answering](https://arxiv.org/pdf/1901.07696v2.pdf)

* Best Method and Code: [PAAG](https://github.com/gsh199449/productqa)

* Last Update: 2019-01-24

* 论文: [电子商务问答中的产品感知应答生成](https://arxiv.org/pdf/1901.07696v2.pdf)

* 最佳方法和代码: [PAAG](https://github.com/gsh199449/productqa)

* 最近更新: 2019-01-24

### MCTest-160

* Paper: [ACL 2016 A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data](https://arxiv.org/pdf/1603.08884v1.pdf)

* Best Method and Code: [syntax, frame, coreference, and word embedding features](https://github.com/Maluuba/mctest-model)

* Last Update: 2018-11-20

* 论文: [ACL 2016 用于稀疏数据机器理解的并行分层模型](https://arxiv.org/pdf/1603.08884v1.pdf)

* 最佳方法和代码: [Parallel-Hierarchical](https://github.com/Maluuba/mctest-model)

* 最近更新: 2018-11-20

