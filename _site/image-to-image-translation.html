<h3 id="state-of-the-art-in-image-to-image-translation">State Of The Art in Image To Image Translation</h3>

<h3 id="cityscapes-labels-to-photo">Cityscapes Labels-to-Photo</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1611.07004v3.pdf">CVPR 2017 Image-to-Image Translation with Conditional Adversarial Networks</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/gan">pix2pix</a></p>
  </li>
  <li>
    <p>Last Update: 2018-10-02</p>
  </li>
</ul>

<h3 id="cityscapes-photo-to-labels">Cityscapes Photo-to-Labels</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1611.07004v3.pdf">CVPR 2017 Image-to-Image Translation with Conditional Adversarial Networks</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/gan">pix2pix</a></p>
  </li>
  <li>
    <p>Last Update: 2018-10-02</p>
  </li>
</ul>

<h3 id="ade20k-outdoor-labels-to-photos">ADE20K-Outdoor Labels-to-Photos</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1903.07291v1.pdf">CVPR 2019 Semantic Image Synthesis with Spatially-Adaptive Normalization</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/NVlabs/SPADE">SPADE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-21</p>
  </li>
</ul>

<h3 id="rafd">RaFD</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1711.09020v3.pdf">CVPR 2018 StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/yunjey/StarGAN">StarGAN</a></p>
  </li>
  <li>
    <p>Last Update: 2019-04-22</p>
  </li>
</ul>

<h3 id="coco-stuff-labels-to-photos">COCO-Stuff Labels-to-Photos</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1903.07291v1.pdf">CVPR 2019 Semantic Image Synthesis with Spatially-Adaptive Normalization</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/NVlabs/SPADE">SPADE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-21</p>
  </li>
</ul>

<h3 id="ade20k-labels-to-photos">ADE20K Labels-to-Photos</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1903.07291v1.pdf">CVPR 2019 Semantic Image Synthesis with Spatially-Adaptive Normalization</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/NVlabs/SPADE">SPADE</a></p>
  </li>
  <li>
    <p>Last Update: 2019-05-21</p>
  </li>
</ul>

<h3 id="aerial-to-map">Aerial-to-Map</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1611.07004v3.pdf">CVPR 2017 Image-to-Image Translation with Conditional Adversarial Networks</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/tensorflow/models/tree/master/research/gan">cGAN</a></p>
  </li>
  <li>
    <p>Last Update: 2018-10-02</p>
  </li>
</ul>

<h3 id="synthia-to-cityscapes">SYNTHIA-to-Cityscapes</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1812.09953v3.pdf"> A Curriculum Domain Adaptation Approach to the Semantic Segmentation of Urban Scenes</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/YangZhang4065/AdaptationSeg">superpixel + color constancy</a></p>
  </li>
  <li>
    <p>Last Update: 2019-02-20</p>
  </li>
</ul>

<h3 id="synthia-fall-to-winter">SYNTHIA Fall-to-Winter</h3>

<ul>
  <li>
    <p>Paper: <a href="https://arxiv.org/pdf/1711.03213v3.pdf">ICML 2018 CyCADA: Cycle-Consistent Adversarial Domain Adaptation</a></p>
  </li>
  <li>
    <p>Best Method and Code: <a href="https://github.com/jhoffman/cycada_release">CyCADA</a></p>
  </li>
  <li>
    <p>Last Update: 2018-11-14</p>
  </li>
</ul>

