---
path: '/stuff/'
title: 'Atari Games'
type: 'PLAYING_GAMES'

layout: nil
---

### State Of The Art in Atari Games  
### Atari游戏的最新进展

### Atari 2600 Montezuma's Revenge

* Paper: [Exploration by Random Network Distillation](https://arxiv.org/pdf/1810.12894v1.pdf)

* Best Method and Code: [RND](https://github.com/openai/random-network-distillation)

* Last Update: 2018-11-22

* 论文: [随机网络蒸馏探索技术](https://arxiv.org/pdf/1810.12894v1.pdf)

* 最佳方法和代码: [RND](https://github.com/openai/random-network-distillation)

* 最近更新: 2018-11-22

### Atari 2600 Venture

* Paper: [Exploration by Random Network Distillation](https://arxiv.org/pdf/1810.12894v1.pdf)

* Best Method and Code: [RND](https://github.com/openai/random-network-distillation)

* Last Update: 2018-11-22

* 论文: [随机网络蒸馏探索技术](https://arxiv.org/pdf/1810.12894v1.pdf)

* 最佳方法和代码: [RND](https://github.com/openai/random-network-distillation)

* 最近更新: 2018-11-22

### Atari 2600 Freeway

* Paper: [NeurIPS 2017 #Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning](https://arxiv.org/pdf/1611.04717v3.pdf)

* Best Method and Code: [TRPO-hash](https://github.com/nhynes/abc)

* Last Update: 2017-12-12

* 论文: [NeurIPS 2017 #探索: 基于计数的深度强化学习探索研究](https://arxiv.org/pdf/1611.04717v3.pdf)

* 最佳方法和代码: [TRPO-hash](https://github.com/nhynes/abc)

* 最近更新: 2017-12-12

### Atari 2600 Frostbite

* Paper: [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581v3.pdf)

* Best Method and Code: [Prior+Duel noop](https://github.com/facebookresearch/Horizon)

* Last Update: 2019-06-03

* 论文: [深度强化学习的对抗网络架构](https://arxiv.org/pdf/1511.06581v3.pdf)

* 最佳方法和代码: [Prior+Duel noop](https://github.com/facebookresearch/Horizon)

* 最近更新: 2019-06-03

### Atari 2600 Q*Bert

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Private Eye

* Paper: [ICML 2017 A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887v1.pdf)

* Best Method and Code: [C51 noop](https://github.com/NervanaSystems/coach)

* Last Update: 2019-06-05

* 论文: [ICML 2017 强化学习的分布视角](https://arxiv.org/pdf/1707.06887v1.pdf)

* 最佳方法和代码: [C51 noop](https://github.com/NervanaSystems/coach)

* 最近更新: 2019-06-05

### Atari 2600 Gravitar

* Paper: [Exploration by Random Network Distillation](https://arxiv.org/pdf/1810.12894v1.pdf)

* Best Method and Code: [RND](https://github.com/openai/random-network-distillation)

* Last Update: 2018-11-22

* 论文: [随机网络蒸馏探索技术](https://arxiv.org/pdf/1810.12894v1.pdf)

* 最佳方法和代码: [RND](https://github.com/openai/random-network-distillation)

* 最近更新: 2018-11-22

### Atari 2600 Seaquest

* Paper: [ICML 2017 A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887v1.pdf)

* Best Method and Code: [C51 noop](https://github.com/NervanaSystems/coach)

* Last Update: 2019-06-05

* 论文: [ICML 2017 强化学习的分布视角](https://arxiv.org/pdf/1707.06887v1.pdf)

* 最佳方法和代码: [C51 noop](https://github.com/NervanaSystems/coach)

* 最近更新: 2019-06-05

### Atari 2600 Space Invaders

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Enduro

* Paper: [ICML 2017 A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887v1.pdf)

* Best Method and Code: [C51 noop](https://github.com/NervanaSystems/coach)

* Last Update: 2019-06-05

* 论文: [ICML 2017 强化学习的分布视角](https://arxiv.org/pdf/1707.06887v1.pdf)

* 最佳方法和代码: [C51 noop](https://github.com/NervanaSystems/coach)

* 最近更新: 2019-06-05

### Atari 2600 Pong

* Paper: [Playing Atari with Deep Reinforcement Learning](https://arxiv.org/pdf/1312.5602v1.pdf)

* Best Method and Code: [DQN best](https://github.com/tensorpack/tensorpack)

* Last Update: 2019-06-07

* 论文: [用深度强化学习玩Atari游戏](https://arxiv.org/pdf/1312.5602v1.pdf)

* 最佳方法和代码: [DQN best](https://github.com/tensorpack/tensorpack)

* 最近更新: 2019-06-07

### Atari 2600 Amidar

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Asterix

* Paper: [ICML 2017 A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887v1.pdf)

* Best Method and Code: [C51 noop](https://github.com/NervanaSystems/coach)

* Last Update: 2019-06-05

* 论文: [ICML 2017 强化学习的分布视角](https://arxiv.org/pdf/1707.06887v1.pdf)

* 最佳方法和代码: [C51 noop](https://github.com/NervanaSystems/coach)

* 最近更新: 2019-06-05

### Atari 2600 Breakout

* Paper: [NeurIPS 2016 Deep Exploration via Bootstrapped DQN](https://arxiv.org/pdf/1602.04621v3.pdf)

* Best Method and Code: [Bootstrapped DQN](https://github.com/tensorflow/models/tree/master/research/deep_contextual_bandits)

* Last Update: 2018-07-23

* 论文: [NeurIPS 2016 通过自举DQN进行深度探索](https://arxiv.org/pdf/1602.04621v3.pdf)

* 最佳方法和代码: [Bootstrapped DQN](https://github.com/tensorflow/models/tree/master/research/deep_contextual_bandits)

* 最近更新: 2018-07-23

### Atari 2600 Alien

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Assault

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Beam Rider

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Kangaroo

* Paper: [Prioritized Experience Replay](https://arxiv.org/pdf/1511.05952v4.pdf)

* Best Method and Code: [Prior noop](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [优先经验回放](https://arxiv.org/pdf/1511.05952v4.pdf)

* 最佳方法和代码: [Prior noop](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Gopher

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Robotank

* Paper: [NeurIPS 2016 Deep Exploration via Bootstrapped DQN](https://arxiv.org/pdf/1602.04621v3.pdf)

* Best Method and Code: [Bootstrapped DQN](https://github.com/tensorflow/models/tree/master/research/deep_contextual_bandits)

* Last Update: 2018-07-23

* 论文: [NeurIPS 2016 通过自举DQN进行深度探索](https://arxiv.org/pdf/1602.04621v3.pdf)

* 最佳方法和代码: [Bootstrapped DQN](https://github.com/tensorflow/models/tree/master/research/deep_contextual_bandits)

* 最近更新: 2018-07-23

### Atari 2600 Bowling

* Paper: [NeurIPS 2016 Learning values across many orders of magnitude](https://arxiv.org/pdf/1602.07714v2.pdf)

* Best Method and Code: [DDQN+Pop-Art noop]()

* 论文: [NeurIPS 2016 跨多个数量级学习数值](https://arxiv.org/pdf/1602.07714v2.pdf)

* 最佳方法和代码: [DDQN+Pop-Art noop]()

### Atari 2600 Up and Down

* Paper: [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783v2.pdf)

* Best Method and Code: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* Last Update: 2019-06-07

* 论文: [深度强化学习的异步方法](https://arxiv.org/pdf/1602.01783v2.pdf)

* 最佳方法和代码: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* 最近更新: 2019-06-07

### Atari 2600 Tutankham

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Time Pilot

* Paper: [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783v2.pdf)

* Best Method and Code: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* Last Update: 2019-06-07

* 论文: [深度强化学习的异步方法](https://arxiv.org/pdf/1602.01783v2.pdf)

* 最佳方法和代码: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* 最近更新: 2019-06-07

### Atari 2600 Name This Game

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Boxing

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Asteroids

* Paper: [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783v2.pdf)

* Best Method and Code: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* Last Update: 2019-06-07

* 论文: [深度强化学习的异步方法](https://arxiv.org/pdf/1602.01783v2.pdf)

* 最佳方法和代码: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* 最近更新: 2019-06-07

### Atari 2600 Zaxxon

* Paper: [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783v2.pdf)

* Best Method and Code: [A3C FF hs](https://github.com/tensorpack/tensorpack)

* Last Update: 2019-06-07

* 论文: [深度强化学习的异步方法](https://arxiv.org/pdf/1602.01783v2.pdf)

* 最佳方法和代码: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* 最近更新: 2019-06-07

### Atari 2600 Ice Hockey

* Paper: [Prioritized Experience Replay](https://arxiv.org/pdf/1511.05952v4.pdf)

* Best Method and Code: [Prior noop](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [优先经验回放](https://arxiv.org/pdf/1511.05952v4.pdf)

* 最佳方法和代码: [Prior noop](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Tennis

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Road Runner

* Paper: [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783v2.pdf)

* Best Method and Code: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* Last Update: 2019-06-07

* 论文: [深度强化学习的异步方法](https://arxiv.org/pdf/1602.01783v2.pdf)

* 最佳方法和代码: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* 最近更新: 2019-06-07

### Atari 2600 Krull

* Paper: [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581v3.pdf)

* Best Method and Code: [Duel noop](https://github.com/facebookresearch/Horizon)

* Last Update: 2019-06-03

* 论文: [深度强化学习的对抗网络架构](https://arxiv.org/pdf/1511.06581v3.pdf)

* 最佳方法和代码: [Duel noop](https://github.com/facebookresearch/Horizon)

* 最近更新: 2019-06-03

### Atari 2600 Demon Attack

* Paper: [ICML 2017 A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887v1.pdf)

* Best Method and Code: [C51 noop](https://github.com/NervanaSystems/coach)

* Last Update: 2019-06-05

* 论文: [ICML 2017 强化学习的分布视角](https://arxiv.org/pdf/1707.06887v1.pdf)

* 最佳方法和代码: [C51 noop](https://github.com/NervanaSystems/coach)

* 最近更新: 2019-06-05

### Atari 2600 Crazy Climber

* Paper: [ICML 2017 A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887v1.pdf)

* Best Method and Code: [C51 noop](https://github.com/NervanaSystems/coach)

* Last Update: 2019-06-05

* 论文: [ICML 2017 强化学习的分布视角](https://arxiv.org/pdf/1707.06887v1.pdf)

* 最佳方法和代码: [C51 noop](https://github.com/NervanaSystems/coach)

* 最近更新: 2019-06-05

### Atari 2600 Centipede

* Paper: [NeurIPS 2016 Learning values across many orders of magnitude](https://arxiv.org/pdf/1602.07714v2.pdf)

* Best Method and Code: [DDQN+Pop-Art noop]()

* 论文: [NeurIPS 2016 跨多个数量级学习数值](https://arxiv.org/pdf/1602.07714v2.pdf)

* 最佳方法和代码: [DDQN+Pop-Art noop]()

### Atari 2600 River Raid

* Paper: [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581v3.pdf)

* Best Method and Code: [Duel noop](https://github.com/facebookresearch/Horizon)

* Last Update: 2019-06-03

* 论文: [深度强化学习的对抗网络架构](https://arxiv.org/pdf/1511.06581v3.pdf)

* 最佳方法和代码: [Duel noop](https://github.com/facebookresearch/Horizon)

* 最近更新: 2019-06-03

### Atari 2600 Wizard of Wor

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Double Dunk

* Paper: [Prioritized Experience Replay](https://arxiv.org/pdf/1511.05952v4.pdf)

* Best Method and Code: [Prior noop](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [优先经验回放](https://arxiv.org/pdf/1511.05952v4.pdf)

* 最佳方法和代码: [Prior noop](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Battle Zone

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Video Pinball

* Paper: [ICML 2017 A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887v1.pdf)

* Best Method and Code: [C51 noop](https://github.com/NervanaSystems/coach)

* Last Update: 2019-06-05

* 论文: [ICML 2017 强化学习的分布视角](https://arxiv.org/pdf/1707.06887v1.pdf)

* 最佳方法和代码: [C51 noop](https://github.com/NervanaSystems/coach)

* 最近更新: 2019-06-05

### Atari 2600 Bank Heist

* Paper: [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581v3.pdf)

* Best Method and Code: [Duel noop](https://github.com/facebookresearch/Horizon)

* Last Update: 2019-06-03

* 论文: [深度强化学习的对抗网络架构](https://arxiv.org/pdf/1511.06581v3.pdf)

* 最佳方法和代码: [Duel noop](https://github.com/facebookresearch/Horizon)

* 最近更新: 2019-06-03

### Atari 2600 Atlantis

* Paper: [Evolution Strategies as a Scalable Alternative to Reinforcement Learning](https://arxiv.org/pdf/1703.03864v2.pdf)

* Best Method and Code: [ES FF (1 hour) noop](https://github.com/openai/evolution-strategies-starter)

* Last Update: 2018-11-22

* 论文: [用作强化学习的可扩展替代的进化策略](https://arxiv.org/pdf/1703.03864v2.pdf)

* 最佳方法和代码: [ES FF (1 hour) noop](https://github.com/openai/evolution-strategies-starter)

* 最近更新: 2018-11-22

### Atari 2600 Star Gunner

* Paper: [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783v2.pdf)

* Best Method and Code: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* Last Update: 2019-06-07

* 论文: [深度强化学习的异步方法](https://arxiv.org/pdf/1602.01783v2.pdf)

* 最佳方法和代码: [A3C LSTM hs](https://github.com/tensorpack/tensorpack)

* 最近更新: 2019-06-07

### Atari 2600 Fishing Derby

* Paper: [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581v3.pdf)

* Best Method and Code: [Duel noop](https://github.com/facebookresearch/Horizon)

* Last Update: 2019-06-03

* 论文: [深度强化学习的对抗网络架构](https://arxiv.org/pdf/1511.06581v3.pdf)

* 最佳方法和代码: [Duel noop](https://github.com/facebookresearch/Horizon)

* 最近更新: 2019-06-03

### Atari 2600 Chopper Command

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Kung-Fu Master

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 HERO

* Paper: [ICML 2017 A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887v1.pdf)

* Best Method and Code: [C51 noop](https://github.com/NervanaSystems/coach)

* Last Update: 2019-06-05

* 论文: [ICML 2017 强化学习的分布视角](https://arxiv.org/pdf/1707.06887v1.pdf)

* 最佳方法和代码: [C51 noop](https://github.com/NervanaSystems/coach)

* 最近更新: 2019-06-05

### Atari 2600 Ms. Pacman

* Paper: [Prioritized Experience Replay](https://arxiv.org/pdf/1511.05952v4.pdf)

* Best Method and Code: [Prior noop](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [优先经验回放](https://arxiv.org/pdf/1511.05952v4.pdf)

* 最佳方法和代码: [Prior noop](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 James Bond

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Berzerk

* Paper: [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581v3.pdf)

* Best Method and Code: [Prior+Duel noop](https://github.com/facebookresearch/Horizon)

* Last Update: 2019-06-03

* 论文: [深度强化学习的对抗网络架构](https://arxiv.org/pdf/1511.06581v3.pdf)

* 最佳方法和代码: [Prior+Duel noop](https://github.com/facebookresearch/Horizon)

* 最近更新: 2019-06-03

### Atari 2600 Defender

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari-57

* Paper: [ICLR 2018 Distributed Prioritized Experience Replay](https://arxiv.org/pdf/1803.00933v1.pdf)

* Best Method and Code: [Ape-X](https://github.com/belepi93/Ape-X)

* Last Update: 2019-04-28

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Solaris

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Phoenix

* Paper: [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581v3.pdf)

* Best Method and Code: [Prior+Duel hs](https://github.com/facebookresearch/Horizon)

* Last Update: 2019-06-03

* 论文: [深度强化学习的对抗网络架构](https://arxiv.org/pdf/1511.06581v3.pdf)

* 最佳方法和代码: [Prior+Duel hs](https://github.com/facebookresearch/Horizon)

* 最近更新: 2019-06-03

### Atari 2600 Pitfall!

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Skiing

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Yars Revenge

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

### Atari 2600 Surround

* Paper: [ICML 2018 Implicit Quantile Networks for Distributional Reinforcement Learning](https://arxiv.org/pdf/1806.06923v1.pdf)

* Best Method and Code: [IQN](https://github.com/google/dopamine)

* Last Update: 2019-06-08

* 论文: [ICML 2018 用于分布式强化学习的隐式分位数网络](https://arxiv.org/pdf/1806.06923v1.pdf)

* 最佳方法和代码: [IQN](https://github.com/google/dopamine)

* 最近更新: 2019-06-08

